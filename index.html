<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Mike Zhang</title>

    <meta name="author" content="Mike Zhang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/icon_flipped.png" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>


  <body>
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align:left;">
                  Mike Zhang
                </p>
                <p style="text-align: justify;">
                I'm a research engineer at the <a href="https://rsl.ethz.ch/">Robotic Systems Lab</a> in ETH Zurich, where I work on mobile manipulation with <a href="https://rsl.ethz.ch/robots-media/alma.html">ALMA</a>, our legged robot with an arm.
                </p>
                <p style="text-align: justify;">
                I did my Master's in Robotics, Systems and Control (with distinction) at ETH Zurich, where I worked on a variety of projects in the topics of geometric computer vision, automated robot design, learning robot control, and high-level task planning with Large Language Models.
                </p>
                <p style="text-align: justify;">
                I also had the chance to work on flying robots at <a href="https://www.flyability.com/">Flyability</a> and <a href="https://verity.net/">Verity</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:mike.zhang.619@gmail.com">Email</a> &nbsp;|&nbsp;
                  <a href="data/mike_zhang_cv.pdf">CV</a> &nbsp;|&nbsp;
                  <a href="https://github.com/clams-casino">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <img style="width:80%;max-width:80%;object-fit: cover; border-radius: 6%;" alt="profile photo" src="images/mike.jpg" class="hoverZoomLink">
              </td>
            </tr>
          </tbody></table>


    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <h2>Publications</h2>
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr>
      <td style="padding:0px;width:38%;vertical-align:middle">
        <video id="tag_mapping" autoplay muted loop width="100%">
          <source src="videos/tag_mapping.mp4"
                  type="video/mp4">
        </video>
      </td>
      <td style="padding:20px;width:62%;vertical-align:top">
      <span class="papertitle">Tag Map: A Text-Based Map for Spatial Reasoning and Navigation<br>with Large Language Models</span>
        </a>
        <br>
        <strong>Mike Zhang</strong>,
        <a href="https://www.linkedin.com/in/kaixian-qu-66a86215a">Kaixian Qu</a>,
        <a href="https://www.linkedin.com/in/vaishakhpatil">Vaishakh Patil</a>,
        <a href="https://n.ethz.ch/~cesarc">Cesar Cadena</a>,
        <a href="https://rsl.ethz.ch/the-lab/people/person-detail.MTIxOTEx.TGlzdC8yNDQxLC0xNDI1MTk1NzM1.html">Marco Hutter</a>
        <br>
        <em>Conference on Robot Learning (CoRL)</em>, 2024
        <br>
        <a href="https://tag-mapping.github.io">project page</a>
        |
        <a href="data/tag_map_paper.pdf">paper</a>
        |
        <a href="https://arxiv.org/abs/2409.15451">arxiv</a>
        <p></p>
        <p style="text-align: justify;">
        We propose to represent a scene as a database of viewpoints indexed by text tags of the recognized things at each viewpoint. The representation is extremely memory efficient and easily integrates with an LLM for planning and spatial reasoning grounded on the scene context.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;vertical-align:middle">
        <video id="door_opening" autoplay muted loop width="100%">
          <source src="videos/door_opening.mp4"
                  type="video/mp4">
        </video>
      </td>
      <td style="padding:20px;vertical-align:top">
			<span class="papertitle">Learning to Open and Traverse Doors with a Legged Manipulator</span>
        </a>
        <br>
        <strong>Mike Zhang</strong>,
				<a href="https://articuno144.github.io">Yuntao Ma</a>,
        <a href="https://takahiromiki.com">Takahiro Miki</a>, 
        <a href="https://rsl.ethz.ch/the-lab/people/person-detail.MTIxOTEx.TGlzdC8yNDQxLC0xNDI1MTk1NzM1.html">Marco Hutter</a>
        <br>
        <em>Conference on Robot Learning (CoRL)</em>, 2024
        <br>
        <a href="https://youtu.be/tQDZXN_k5NU">video</a>
        |
        <a href="data/door_opening_paper.pdf">paper</a>
        |
        <a href="https://arxiv.org/abs/2409.04882">arxiv</a>
        <p></p>
        <p style="text-align: justify;">
				We train a legged robot with an arm to robustly traverse through a variety of doors without prior knowledge of the 
        door's opening direction, instead estimating these properties during the task interaction.
        </p>
      </td>
    </tr>


    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <h2>Projects</h2>
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <tr>
      <td style="padding:20px;width:38%;vertical-align:middle">
        <img src='images/terrain_filtering.png' width="100%">
      </td>
      <td style="padding:20px;width:62%;vertical-align:top">
			<span class="papertitle">Semantic Front-End Filter Going to the Jungle</span>
        </a>
        <br>
        <em>Perception and Learning for Robotics, ETH Zurich</em>, 2022
        <br>
        <a href="data/terrain_filter_poster.pdf">poster</a>
        <p></p>
        <p style="text-align: justify;">
				Self-supervised learning of a filter for reconstructing the walkable terrain in dense vegetation from semantic point cloud measurements.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:10px;vertical-align:middle">
        <img src='images/morphology_rl.png' width="100%">
      </td>
      <td style="padding:20px;vertical-align:top">
			<span class="papertitle">On the Origins of Robot Morphologies</span>
        </a>
        <br>
        <em>Foundations of Reinforcement Learing, ETH Zurich</em>, 2021
        <br>
        <a href="data/morphology_design_with_rl_report.pdf">report</a>
        |
        <a href="data/morphology_design_with_rl_poster.pdf">poster</a>
        <p></p>
        <p style="text-align: justify;">
				A policy is trained using Reinforcement Learning on evolutionary rollouts, learning how to best change a robot's morphology for optimizing its performance in a given task.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:10px;vertical-align:middle">
        <img src='images/slam_initialization.png' width="100%">
      </td>
      <td style="padding:20px;vertical-align:middle">
			<span class="papertitle">Evaluating Visual Odometry & SLAM Initialization Methods<br>for Arbitrary Multi-Camera Rigs</span>
        </a>
        <br>
        <em>3D Vision, ETH Zurich</em>, 2021
        <br>
        <a href="data/evaluating_multi_camera_slam_initialization_report.pdf">report</a>
        <p></p>
        <p style="text-align: justify;">
				A study on the various factors contributing to the initialization quality for visual odometry and SLAM pipelines in multi-camera systems.
        </p>
      </td>
    </tr>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
      <tr>
      <td>
        <h2>Teaching</h2>
        <br>
        <a href="https://rsl.ethz.ch/education-students/lectures/robotdynamics.html">Robot Dynamics</a>
        <br>
        Head Teaching Assistant
        <br>
        ETH Zurich, Fall 2024
        <br><br>
        <a href="https://idsc.ethz.ch/education/lectures/model-predictive-control1.html">Advanced Model Predictive Control</a>
        <br>
        ETH Zurich, Spring 2023
        <br><br>
        <a href="https://rsl.ethz.ch/education-students/lectures/ros.html">Programming for Robotics - ROS</a>
        <br>
        ETH Zurich, Spring 2023
        <br><br>
        <a href="https://rsl.ethz.ch/education-students/lectures/robotdynamics.html">Robot Dynamics</a>
        <br>
        ETH Zurich, Fall 2021
        <br><br>
      </td>
      </tr>
    </tbody></table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
      <tr>
      <td>
        <h2>Misc</h2>
        <br>
        <video id="teaser" autoplay muted loop width="50%">
          <source src="videos/paddy.mp4"
                  type="video/mp4">
        </video>
      </td>
      </tr>
    </tbody></table>


        </td>
      </tr>
    </table>
  </body>
</html>
